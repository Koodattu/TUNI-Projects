%!TEX root = ../main.tex
%********************************
\chapter{Conclusion}
The Voice-Guided Imaging project successfully demonstrates how self-hosted AI models can be integrated into a modular application for generating and editing multimedia content using natural language commands. By combining speech-to-text, intent recognition, and generative AI models, the application serves as a proof-of-concept for building multi-model AI pipelines that operate locally.

The project highlights the feasibility of running complex AI workflows without relying on cloud-based services, addressing concerns about privacy, cost, and control. Through the use of quantization and dynamic model management, it also showcases methods to optimize GPU memory usage and handle resource-intensive tasks effectively.

While the application delivers high-quality outputs and supports real-time interaction, it also reveals the limitations of local hosting, including scalability challenges and hardware requirements. These insights provide a foundation for future improvements, such as multi-user support, hardware optimization, and hybrid architectures that combine local and cloud resources.

The Voice-Guided Imaging application is not only a functional tool but also a learning platform for exploring generative AI systems. It paves the way for further research into improving performance, expanding capabilities, and comparing self-hosted and proprietary AI solutions — topics that will be addressed in future work and the author’s thesis.